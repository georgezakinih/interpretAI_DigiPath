{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of concept_attribution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maragraziani/interpretAI_DigiPath/blob/main/2DCNNs/concept_attribution_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3qLbfz7o4s"
      },
      "source": [
        "# Concept attribution with Regression Concept Vectors\n",
        "This notebook wil walk you through the implementation of one approach to concept-based explanability, namely that of Regression Concept Vectors (RCVs). We will directly experiment with pathology images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5B1sOSbdPe_0",
        "outputId": "3bdf49f0-b887-4ec0-bdb5-915cf5a5d341"
      },
      "source": [
        "!pip install rcvtool"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rcvtool\n",
            "  Downloading https://files.pythonhosted.org/packages/00/c6/18c038d7bcaeb95c093188501b7162422ee8dc3823a3e028e959c63a9c86/rcvtool-0.1.5.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rcvtool) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from rcvtool) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from rcvtool) (0.16.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from rcvtool) (2.4.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from rcvtool) (2.4.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from rcvtool) (0.10.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (7.1.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->rcvtool) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->rcvtool) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->rcvtool) (2.10.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->rcvtool) (3.7.4.3)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->rcvtool) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->rcvtool) (1.1.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->rcvtool) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rcvtool) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rcvtool) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rcvtool) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->rcvtool) (0.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (54.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (1.28.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->rcvtool) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->rcvtool) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->rcvtool) (3.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->rcvtool) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->rcvtool) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->rcvtool) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->rcvtool) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->rcvtool) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->rcvtool) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->rcvtool) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->rcvtool) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->rcvtool) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->rcvtool) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->rcvtool) (3.1.0)\n",
            "Building wheels for collected packages: rcvtool\n",
            "  Building wheel for rcvtool (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rcvtool: filename=rcvtool-0.1.5-cp37-none-any.whl size=8716 sha256=33bef5fbf2857dafb13e42c14710096836a93364d72862eee2d27b16e5a884cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/66/2b/8091875f34198257a1317c4ee538e46d077569b8f3d8136bec\n",
            "Successfully built rcvtool\n",
            "Installing collected packages: rcvtool\n",
            "Successfully installed rcvtool-0.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnYCWQcu70Ve"
      },
      "source": [
        "import tensorflow.keras\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adadelta\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import time\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8zY3bah71Je"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AJwJ-TX74Zp",
        "outputId": "c240d9bc-d8b9-4a00-b868-8953e2380b20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O0leF1x8A1t"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "seed=0\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA51RRqr8UqQ",
        "outputId": "3586634d-40b9-4f16-92f2-af9adba1dc86"
      },
      "source": [
        "# BATCH GENERATORS AND STAIN NORMALIZATION FUNCTIONS\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CNNinterpret')\n",
        "from normalizers import *\n",
        "global normalizer\n",
        "\n",
        "def get_normalizer(patch, save_folder=''):\n",
        "    normalizer = ReinhardNormalizer()\n",
        "    normalizer.fit(patch)\n",
        "    np.save('{}/normalizer'.format(save_folder),normalizer)\n",
        "    np.save('{}/normalizing_patch'.format(save_folder), patch)\n",
        "    print('Normalisers saved to disk.')\n",
        "    return normalizer\n",
        "\n",
        "normalizer=get_normalizer(np.load('/content/drive/MyDrive/CNNinterpret/normalizing_patch.npy'))\n",
        "\n",
        "def normalize_patch(patch, normalizer):\n",
        "    return np.float64(normalizer.transform(np.uint8(patch)))\n",
        "\n",
        "def get_batch_data(patch_list, labels, batch_size=32):\n",
        "    num_samples=len(patch_list)\n",
        "    while True:\n",
        "        for offset in range(0,num_samples, batch_size):\n",
        "            batch_x = []\n",
        "            batch_y = []\n",
        "            batch_samples=patch_list[offset:offset+batch_size]\n",
        "            for patch_id in range(len(batch_samples)):\n",
        "                #print(len(batch_samples))\n",
        "                patch=patch_list[patch_id]\n",
        "                patch=normalize_patch(patch, normalizer)\n",
        "                # VGG input is fixed to 224,224 for finetuning imagenet weights\n",
        "                patch=cv2.resize(patch, (224,224)) \n",
        "                patch=tensorflow.keras.applications.vgg16.preprocess_input(patch)\n",
        "                label=labels[patch_id]\n",
        "                batch_x.append(patch)\n",
        "                batch_y.append(label)\n",
        "            \n",
        "            batch_x=np.asarray(batch_x, dtype=np.float32)/255.\n",
        "            batch_y=np.asarray(batch_y, dtype=np.float32)\n",
        "            yield batch_x, batch_y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using brightness standardization\n",
            "Normalisers saved to disk.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkrEVxsB9AnR"
      },
      "source": [
        "import h5py as hd\n",
        "y_test = np.asarray(hd.File('/content/drive/MyDrive/CNNinterpret/camelyonpatch_level_2_split_valid_y.h5', 'r')['y'][:])\n",
        "x_test = np.asarray(hd.File('/content/drive/MyDrive/CNNinterpret/camelyonpatch_level_2_split_valid_x.h5', 'r')['x'][:])\n",
        "y_test=y_test[:].ravel()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y95Twe859Rai",
        "outputId": "d3acfbd8-443d-4d4b-b0a3-c7a391fe96b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Let's load the VGG weights finetuned on the histopathology dataset.\n",
        "base_model=tensorflow.keras.applications.VGG16()\n",
        "predictions=tensorflow.keras.layers.Dense(1,activation='sigmoid')(base_model.layers[-2].output)\n",
        "vgg_histo_model = tensorflow.keras.Model(base_model.input, predictions)\n",
        "vgg_histo_model.load_weights('/content/drive/MyDrive/CNNinterpret/weights.h5')\n",
        "vgg_histo_model.compile(loss=tensorflow.keras.losses.binary_crossentropy, optimizer=tensorflow.keras.optimizers.SGD(lr=1e-4), metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdeuUWNOJ5dF",
        "outputId": "9f764351-0ae2-4554-cfff-0acc79576128"
      },
      "source": [
        "vgg_histo_model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 4097      \n",
            "=================================================================\n",
            "Total params: 134,264,641\n",
            "Trainable params: 134,264,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gFjiUZk9b-a",
        "outputId": "d2641c51-231d-4a17-9025-739f75a0a246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Let's extract the concept measures\n",
        "import rcvtool as rcv\n",
        "NSAMPLES=50\n",
        "test_generator = get_batch_data(x_test[:NSAMPLES], y_test[:NSAMPLES])\n",
        "\n",
        "layer = 'block5_conv3'\n",
        "all_cm=np.zeros(NSAMPLES)\n",
        "all_acts=np.zeros((NSAMPLES, 512))\n",
        "\n",
        "i=0\n",
        "for step in range(NSAMPLES//BATCH_SIZE):\n",
        "  x_b, y_b = test_generator.__next__()\n",
        "  cm_b=[]\n",
        "  for x in x_b:\n",
        "    cm_b.append(rcv.get_texture_measure(x, mtype='contrast')) \n",
        "  all_cm[i:i+len(cm_b)]=cm_b\n",
        "  acts_b=rcv.get_batch_activations(vgg_histo_model, 'block5_conv3',x_b,pooling='AVG')\n",
        "  all_acts[i:i+len(acts_b)]=acts_b\n",
        "  i+=len(x_b)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EqiE-uGI80I",
        "outputId": "0661fe97-ab99-4633-c198-3d0bf5b92125"
      },
      "source": [
        "contrast_vector = rcv.get_rcv(all_acts,all_cm,type='global linear', evaluation=True, verbose=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global linear regression under euclidean assumption\n",
            "Random state:  1\n",
            "R2:  1.0\n",
            "TEST mse: 398.48120179273263, r2: 0.9594215068685689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdwYqnFCPLOm"
      },
      "source": [
        "contrast_vector=contrast_vector.params\n",
        "contrast_vector=contrast_vector[1:]\n",
        "contrast_vector/=np.linalg.norm(contrast_vector)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PbYopg3O6NK"
      },
      "source": [
        "\"\"\" Functions to compute conceptual sensitivity scores \"\"\"\n",
        "def get_directional_derivative(model, rcv_vector, reference_layer, class_id, input_image):\n",
        "  def gap(x):\n",
        "        \"\"\"Utility function to perform gap to a tensor \"\"\"\n",
        "        return tf.keras.backend.mean(x, axis=(1,2))\n",
        "  y_c = model.output[0, class_id]\n",
        "  conv_output = model.get_layer(reference_layer).output\n",
        "  grads = tf.keras.backend.gradients(y_c, conv_output)[0]\n",
        "  grads = gap(grads)\n",
        "  directional_derivative = tf.matmul(grads, tf.expand_dims(tf.convert_to_tensor(rcv_vector, dtype=tf.float32), axis=1))\n",
        "  get_derivative = tf.keras.backend.function([model.input], [directional_derivative])\n",
        "  return get_derivative(input_image) [0]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im3ZiDLNyr_f"
      },
      "source": [
        "x_b, y_b = test_generator.__next__()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUrJInKDQFnS"
      },
      "source": [
        "N_TEST_SAMPLES=10\n",
        "conceptual_sensitivities=[]\n",
        "for i in range(N_TEST_SAMPLES):\n",
        "    conceptual_sensitivities.append(get_directional_derivative(vgg_histo_model, contrast_vector, 'block5_conv3', 0, np.expand_dims(x_b[i],axis=0))[0][0])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEmMcFtRSxM0",
        "outputId": "310e7dfb-3da7-4ed9-fe00-48d55ba054fb"
      },
      "source": [
        "conceptual_sensitivities"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.000206186,\n",
              " 0.00027738482,\n",
              " 0.00031645334,\n",
              " 0.00012242963,\n",
              " 0.0002872779,\n",
              " 0.00012964806,\n",
              " 0.00025965975,\n",
              " 8.393503e-05,\n",
              " 0.00029746583,\n",
              " 9.536054e-05]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wprLnFVF2G6N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}